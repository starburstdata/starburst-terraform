# Starburst-Terraform deployment for Google Cloud
Deployment scripts built for Google Cloud.

### Prerequisites
Ensure you have [gcloud cli](https://cloud.google.com/sdk/docs/install), [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/) and [helm](https://helm.sh/docs/intro/install/) installed and configured according to the cloud provider's documentation.

Ensure that the Google Cloud project you are working in has the following APIs enabled:

*These commands can be run from your command line*
```
gcloud services enable sqladmin.googleapis.com
gcloud services enable sql-component.googleapis.com
gcloud services enable dns.googleapis.com
gcloud services enable storage-api.googleapis.com
gcloud services enable storage-component.googleapis.com
gcloud services enable storage.googleapis.com
gcloud services enable compute.googleapis.com
gcloud services enable container.googleapis.com
```

## Set up
1. Create a Service Account and generate a key file for Terraform to work with. Ensure that the service account includes the following IAM permissions:

    - Kubernetes Engine Admin
    - DNS Administrator
    - Editor
    - Service Networking Admin
    - Storage Admin

    You can use the Google Cloud console to do this, or you can run these command using the Google Cloud cli, (replace the placeholder variables in CAPS with your own values):
```
gcloud iam service-accounts create SERVICE_ACCOUNT_ID --description="DESCRIPTION" --display-name="DISPLAY_NAME"

gcloud iam service-accounts keys create key-file --iam-account=SERVICE_ACCOUNT_EMAIL

gcloud projects add-iam-policy-binding MY_PROJECT --member=serviceAccount:SERVICE_ACCOUNT_EMAIL --role=roles/editor

gcloud projects add-iam-policy-binding MY_PROJECT --member=serviceAccount:SERVICE_ACCOUNT_EMAIL --role=roles/bigquery.admin

gcloud projects add-iam-policy-binding MY_PROJECT --member=serviceAccount:SERVICE_ACCOUNT_EMAIL --role=roles/container.admin

gcloud projects add-iam-policy-binding MY_PROJECT --member=serviceAccount:SERVICE_ACCOUNT_EMAIL --role=roles/dns.admin

gcloud projects add-iam-policy-binding MY_PROJECT --member=serviceAccount:SERVICE_ACCOUNT_EMAIL --role=roles/servicenetworking.serviceAgent

gcloud projects add-iam-policy-binding MY_PROJECT --member=serviceAccount:SERVICE_ACCOUNT_EMAIL --role=roles/storage.admin
```

***Hint**: the SERVICE_ACCOUNT_EMAIL should translate to SERVICE_ACCOUNT_ID@MY_PROJECT.iam.gserviceaccount.com*

2. Save a copy of your Starburst license locally

3. Edit the `terraform.tfvars` file for your environment. For convenience and to ensure you don't accidentally check any sensitive values back into the GitHub repo, set any sensitive values in a separate input variables file ending in: `.auto.tfvars` (e.g. `sensitive.auto.tfvars` and add it to `.gitignore`) file or as global variables (TF_VAR_*) on your local machine:
    - `project`
    - `credentials` *(point to your local file)*
    - `sb_license` *(point to your local file)*
    - `sa_name`
    - `email`
    - `repo_username`
    - `repo_password`

**Note:** You do not need to specify the Pod size of the Starburst workers. This is calculated automatically based on the instance type used in the worker node pool.

4. Create a workspace in Terraform for your deployment:
```
terraform workspace new ${your-workspace-name}
```
5. Initialize the Terraform environment:
```
terraform init
```
6. Deploy your environment:
```
terraform apply
```

## Undeploy
To delete all resources created in this deployment:
```
terraform destroy
```
*Tip: GKE authentication tokens expire after an hour, so if you are attempting to tear down the infrastructure after a prolonged period of time, rerun: `terraform apply` to refresh the token before you run the destroy command*

___
## Input Parameters
|  Parameter | Description | Required | Default |
|---|---|---|---|
| admin_pass | Password override for the `admin_user`. Autogenerated by default. Set this when you want to define your own password for the admin user. Note: If you are deploying with Ranger with an existing Ranger database, set this to the existing Ranger admin user password | no |  |
| admin_user | Admin login credentials for Ranger | yes | sbadmin |
| create_bucket | Should the cloud storage bucket be created? | no | true |
| create_hive | Should the Hive server resource be deployed? | no | true |
| create_k8s | Should the cloud K8s cluster be created? | no | true |
| create_nginx | Should the Nginx controller be deployed? | no | true |
| create_ranger | Should Ranger be deployed? | no | true |
| create_rds | Should the PostgreSQL instance be deployed? | no | true |
| create_trino | Should Starburst (Trino) be deployed? | no | true |
| create_vpc | Should the cloud vpc/vnet be created? | no | true |
| credentials | The Service Account credentials json file | yes |  |
| deployment_id | Custom deployment identifier override. When not set, the system will autogenerate a unique 8 alphanumeric value to identify the deployment infrastructure. If manually overriden, ensure that you are not using a value from an existing deployment. | no |  |
| dns_zone | The DNS zone to deploy applications to | no |  |
| dns_zone_name | the DNS name in Google Cloud | no |  |
| email | Your email address. Required if you need to deploy Nginx | no |  |
| ex_hive_server_url | An existing Hive Server to point your configuration to? | no |  |
| ex_vpc_id | An existing VPC to deploy into | no |  |
| primary_node_type | The VM machine type in the primary pool | no | e2-standard-8 |
| primary_pool_size | The size of the base pool (runs all apps besides Trino worker nodes) | no | 1 |
| project | The Google Cloud Project | yes |  |
| reg_pass1 | Password override for addional user #1. Autogenerated by default. | no |  |
| reg_pass2 | Password override for addional user #2. Autogenerated by default. | no |  |
| reg_user1 | Additional user login to Starburst | yes | sbuser1 |
| reg_user2 | Additional user login to Starburst | yes | sbuser2 |
| region | The Google Cloud region | yes |  |
| registry | Starburst registry in Harbor | yes | harbor.starburstdata.net/starburstdata |
| repo_password | Login password to the Harbor repository | yes |  |
| repo_username | Login user for the Harbor repository | yes |  |
| repo_version | Starburst release to be deployed. This includes all components | yes | 355.0.0 |
| repository | Starburst Helm repository | yes | https://harbor.starburstdata.net/chartrepo/starburstdata |
| sa_name | The Google Service Account name | yes |  |
| sb_license | The Starburst license file | yes |  |
| tags | map of keys and values for tagging cloud resources | no | {manager = "starburst-terraform"} |
| use_ondemand | Should Terraform provision a on-demand instance worker node pool? | no | true |
| use_preemptible | Should Terraform provision a preemptible instance worker node pool? | no | true |
| wait_this_long | default time to wait on resources to finalize. Currently only used to wait for Postgres K8s LoadBalancer service to complete | no | 60s |
| worker_node_type | The VM machine type in the worker pool | no | e2-standard-4 |
| worker_pool_max_size | The maximum size of the worker pool (worker pool is reserved for the Trino workers) | no | 10 |
| worker_pool_max_size | The maximum size of the worker pool (worker pool is reserved for the Trino workers) | no | 10 |
| worker_pool_min_size | The minimum size of the worker pool (worker pool is reserved for the Trino workers) | no | 1 |
| worker_pool_min_size | The minimum size of the worker pool (worker pool is reserved for the Trino workers) | no | 1 |
| zone | the Google Cloud zone within the region | yes |  |
___
## Default Yaml Files
|  Parameter | Description | Required | Default |
|---|---|---|---|
| hive_yaml_file | Default values.yaml for `starburst-hive` Helm chart | yes | hms_values.yaml.tpl |
| trino_yaml_files | Default values.yaml for `starburst-enterprise` Helm chart. Note that there are multiple yaml files for this chart, broken out by related components. The application determines which files to layer onto the deployment based on the user's configuration selection criteria. e.g. if Ranger is not being deployed, then `trino_values.03.ranger.tpl` will be omitted. Note: that each file's configuration is successively applied - meaning that values in the later files will overwrite the same value in the previous files. The full path to the file should be included with the name. | yes | ["trino_values.01.base.tpl", "trino_values.02.auth.tpl", "trino_values.03.ranger.tpl", "trino_values.04.insights.tpl", "trino_values.05.catalogs.tpl", `custom_trino_yaml_file`] |
| ranger_yaml_file | Default values.yaml for `starburst-ranger` Helm chart | yes | ranger_values.yaml.tpl |
| operator_yaml_file | Default values.yaml for `starburst-presto-helm-operator` Helm chart | yes | operator_values.yaml.tpl |
| postgres_yaml_file | Default values.yaml for Bitnami `postgresql` Helm chart | yes | postgresql.yaml.tpl |
| cloudbeaver_values.yaml.tpl | Default values.yaml for `CloudBeaver` Helm chart | yes | cloudbeaver_values.yaml.tpl |
| custom_trino_yaml_file | An optional user-defined yaml file for the Starburst-Enterprise deployment. Use this to override any of the default cluster configuration or to add additional data catalogs for your environment | no |  |
| custom_ranger_yaml_file | An optional user-defined yaml file for the Ranger deployment. Use this to override any of the default configuration | no |  |
| custom_hive_yaml_file | An optional user-defined yaml file for the Hive deployment. Use this to override any of the default configuration. | no |  |
___

## Object Storage parameters for Hive
|  Parameter | Description | Required | Default |
|---|---|---|---|
| gcp_cloud_key_secret | json file containing your Service Account's cloud credentials  | no |  |
| adl_oauth2_client_id | Azure SP ClientID | no |  |
| adl_oauth2_credential | Azure SP Password | no |  |
| adl_oauth2_refresh_url | Azure Oauth2 token refresh URL | no |  |
| s3_access_key | AWS IAM ACCESS_KEY | no |  |
| s3_endpoint | S3 endpoint | no |  |
| s3_region | AWS region to access the S3 endpoint | no |  |
| s3_secret_key | AWS IAM SECRET_KEY | no |  |
| abfs_access_key | Storage account access key | no |  |
| abfs_storage_account | Storage account name | no |  |
| abfs_auth_type | ABFS access type. Can be `accessKey` or `oauth` | no | oauth |
| abfs_client_id | Azure SP ClientID | no |  |
| abfs_endpoint | OAuth2 token refresh endpoint. You can find this in the Azure portal under: `Azure Active Directory > App Registrations > <your-app> > Endpoints` | no |  |
| abfs_secret | Azure SP Password | no |  |
| wasb_access_key | Storage account access key | no |  |
| wasb_storage_account | Storage account name | no |  |
___

## External RDS overrides
*If you have existing databases for these components, you can point to them with these override input parameters. Can be overridden on an individual basis.*
|  Parameter | Description | Required | Default |
|---|---|---|---|
| ex_hive_instance | Existing RDS instance to point your Hive Server to. If this is set, the application will point the Hive Server to this existing Hive metastore DB | no |  |
| ex_hive_port | Hive Database instance port | no |  |
| ex_hive_db | Hive database name (usually `hive` or `hms`) | no |  |
| ex_hive_db_user | User that can connect to the Hive Database | no |  |
| ex_hive_db_password | Password for the `ex_hive_db_user` | no |  |
| ex_ranger_instance | Existing RDS instance to point Ranger to. If set, the application will point to this existing Ranger database store. Note: To avoid any errors, you should also set all related `ex_ranger_?` passwords. | no |  |
| ex_ranger_port | Ranger Database instance port | no |  |
| ex_ranger_db | Ranger database name (usually `ranger`) | no |  |
| ex_ranger_root_user | Database admin user that can connect to the Ranger Database. This should be the `postgres` user or a suitable sysadmin user with the same privileges | no |  |
| ex_ranger_root_password | Password for the `ex_ranger_root_user` | no |  |
| ex_ranger_db_user | The database user that the Ranger application will use (default is `ranger`) | no |  |
| ex_ranger_db_password | Password for `ex_ranger_db_user` | no |  |
| ex_ranger_admin_pwd | Password for Internal account created by Ranger. Corresponds to `admin.passwords.admin` in the Ranger yaml file. Set this to an existing value when connecting to an existing Ranger database | no |  |
| ex_ranger_keyadmin_pwd | Password for Internal account created by Ranger. Corresponds to `admin.passwords.keyadmin` in the Ranger yaml file. Set this to an existing value when connecting to an existing Ranger database | no |  |
| ex_ranger_service_pwd | Password for Internal account created by Ranger. Corresponds to `admin.passwords.service` in the Ranger yaml file. Set this to an existing value when connecting to an existing Ranger database | no |  |
| ex_ranger_tagsync_pwd | Password for Internal account created by Ranger. Corresponds to `admin.passwords.tagsync` in the Ranger yaml file. Set this to an existing value when connecting to an existing Ranger database | no |  |
| ex_ranger_usersync_pwd | Password for Internal account created by Ranger. Corresponds to `admin.passwords.usersync` in the Ranger yaml file. Set this to an existing value when connecting to an existing Ranger database | no |  |
| ex_insights_instance | Existing RDS instance to point Starburst Insights to. When set, the application will point the Starburst Insights application to this existing data store. | no |  |
| ex_insights_port | Insights Database instance port | no |  |
| ex_insights_db | Insights database name (usually `insights`) | no |  |
| ex_insights_db_user | User that can connect to the Starburst Insights Database | no |  |
| ex_insights_db_password | Password for the `ex_insights_db_user` | no |  |