# Starburst-Terraform deployment for AWS
Deployment scripts built for AWS.

### Prerequisites
Ensure you have [aws cli](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html), [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/) and [helm](https://helm.sh/docs/intro/install/) installed and configured according to the cloud provider's documentation.

## Set up
1. Ensure that your `aws cli` has been preconfigured with a user that has the following permissions:
    - `AdministratorAccess`
    - `IAMFullAccess`
    - `AmazonEC2FullAccess`
    - `AutoScalingFullAccess`
    - `AmazonS3FullAccess`
    - `AmazonEKSClusterPolicy`
    - `AmazonEKSServicePolicy`

2. Copy your Starburst license to a local directory

3. Copy the `terraform.tfvars.example` file to `terraform.tfvars` and edit it to suit your environment. Pay particular attention to these values:
    - `sb_license`      *(point to your local file)*
    - `dns_zone`        *(The Route53 zone name to use to create A record dns entries for the application)*
    - `email`           *(Need an email to request a cert from letsencrypt.org)*
    - `repo_username`   *(access to the Starburst Harbor Helm chart repository)*
    - `repo_password`   *(access to the Starburst Harbor Helm chart repository)*
    - `s3_role`         *(IAM policies to attach to the cluster nodes. Provides access to S3 & Glue)*
    - `map_roles`       *(Optional: Map an IAM role to the cluster. Useful if you use a different user to view the cluster in the AWS UI)*
    - `tags`            *(Optional: Custom tags for your resources)*

**Note:** You do not need to specify the Pod size of the Starburst workers. This is calculated automatically based on the instance type used in the worker node pool.

4. Create a workspace in Terraform for your deployment:
```
terraform workspace new ${your-workspace-name}
```
5. Initialize the Terraform environment:
```
terraform init
```
6. Deploy your environment:
```
terraform apply
```

## Undeploy
To delete all resources created in this deployment:
```
terraform destroy
```

___
## Input Parameters
|  Parameter | Description | Required | Default |
|---|---|---|---|
| admin_pass | Password override for the `admin_user`. Autogenerated by default. Set this when you want to define your own password for the admin user. Note: If you are deploying with Ranger with an existing Ranger database, set this to the existing Ranger admin user password | no |  |
| admin_user | Admin login user for Starburst & Ranger | yes | sbadmin |
| capacity_type | EC2 type in the worker node pool: can select either `SPOT` or `ON_DEMAND` depending on preference | no | SPOT |
| cluster_autoscaler_tag | Cluster Autoscaler container version. Note, the major.minor version should match your Kubernetes version. | no | v1.18.3 |
| cluster_autoscaler_version | Version of the cluster_autoscaler Helm chart to be deployed | no | 9.3.0 |
| create_bucket | Should the cloud storage bucket be created? | no | true |
| create_cluster_autoscaler | Should the kubernetes cluster_autoscaler server be deployed? | no | true |
| create_hive | Should the Hive server resource be deployed? | no | true |
| create_k8s | Should the cloud K8s cluster be created? | no | true |
| create_metrics_server | Should the metrics server be deployed to the cluster? Required to support the cluster autoscaler | no | true |
| create_nginx | Should the Nginx controller be deployed? | no | true |
| create_ranger | Should Ranger be deployed? | no | true |
| create_rds | Should the PostgreSQL instance be deployed? | no | true |
| create_trino | Should Starburst (Trino) be deployed? | no | true |
| create_vpc | Should the cloud vpc/vnet be created? | no | true |
| deployment_id | Custom deployment identifier override. When not set, the system will autogenerate a unique 8 alphanumeric value to identify the deployment infrastructure. If manually overriden, ensure that you are not using a value from an existing deployment. | no |  |
| dns_zone | The DNS zone to deploy applications to | no |  |
| email | Your email address. Required if you need to deploy Nginx | no |  |
| ex_hive_server_url | An existing Hive Server to point your configuration to? | no |  |
| ex_vpc_id | An existing VPC to deploy into | no |  |
| map_roles | Additional IAM role to attach to the EKS cluster, to allow others access to the resource in AWS | no |  |
| metrics_server_version | Version of the metrics server Helm chart to be deployed | no | 5.8.7 |
| primary_node_type | The EC2 machine type in the primary pool | no | m5.2xlarge |
| primary_pool_size | The size of the base pool (runs all apps besides Trino worker nodes) | no | 1 |
| reg_pass1 | Password override for addional user #1. Autogenerated by default. | no |  |
| reg_pass2 | Password override for addional user #2. Autogenerated by default. | no |  |
| reg_user1 | Additional user login to Starburst | yes | sbuser1 |
| reg_user2 | Additional user login to Starburst | yes | sbuser2 |
| region | The AWS region | yes |  |
| registry | Starburst registry in Harbor | yes | harbor.starburstdata.net/starburstdata |
| repo_password | Login password to the Harbor repository | yes |  |
| repo_username | Login user for the Harbor repository | yes |  |
| repo_version | Starburst release to be deployed | yes | 355.0.0 |
| repository | Starburst Helm repository | yes | https://harbor.starburstdata.net/chartrepo/starburstdata |
| s3_role | S3 permission role which will be attached to the EKS nodes to allow S3 access to these nodes. With the role in place, you do not need to set up S3 access via IAM keys in the Starburst-Hive yaml. | no |  |
| sb_license | The Starburst license file | yes | N/A |
| tags | map of keys and values for tagging cloud resources | no | {manager = "starburst-terraform"} |
| worker_autoscaling_max_size | Maximum size of the Starburst worker replicas. Value corresponds to `maxReplicas` in yaml | no | 10 |
| worker_autoscaling_min_size | Minimum size of the Starburst worker replicas. Value corresponds to `minReplicas` in yaml | no | 1 |
| worker_node_type | The EC2 machine type in the worker pool | no | m5.xlarge |
| worker_pool_max_size | The maximum size of the worker pool (worker pool is reserved for the Trino workers) | no | 10 |
| worker_pool_min_size | The minimum size of the worker pool (worker pool is reserved for the Trino workers) | no | 1 |
| zone | the AWS zone within the region | yes |  |
___
## Default Yaml Files
|  Parameter | Description | Required | Default |
|---|---|---|---|
| hive_yaml_file | Default values.yaml for `starburst-hive` Helm chart | yes | hms_values.yaml.tpl |
| trino_yaml_files | Default values.yaml for `starburst-enterprise` Helm chart. Note that there are multiple yaml files for this chart, broken out by related components. The application determines which files to layer onto the deployment based on the user's configuration selection criteria. e.g. if Ranger is not being deployed, then `trino_values.03.ranger.tpl` will be omitted. Note: that each file's configuration is successively applied - meaning that values in the later files will overwrite the same value in the previous files. The full path to the file should be included with the name. | yes | ["trino_values.01.base.tpl", "trino_values.02.auth.tpl", "trino_values.03.ranger.tpl", "trino_values.04.insights.tpl", "trino_values.05.catalogs.tpl", `custom_trino_yaml_file`] |
| ranger_yaml_file | Default values.yaml for `starburst-ranger` Helm chart | yes | ranger_values.yaml.tpl |
| operator_yaml_file | Default values.yaml for `starburst-presto-helm-operator` Helm chart | yes | operator_values.yaml.tpl |
| postgres_yaml_file | Default values.yaml for Bitnami `postgresql` Helm chart | yes | postgresql.yaml.tpl |
| cloudbeaver_values.yaml.tpl | Default values.yaml for `CloudBeaver` Helm chart | yes | cloudbeaver_values.yaml.tpl |
| custom_trino_yaml_file | An optional user-defined yaml file for the Starburst-Enterprise deployment. Use this to override any of the default cluster configuration or to add additional data catalogs for your environment | no |  |
| custom_ranger_yaml_file | An optional user-defined yaml file for the Ranger deployment. Use this to override any of the default configuration | no |  |
| custom_hive_yaml_file | An optional user-defined yaml file for the Hive deployment. Use this to override any of the default configuration. | no |  |
___

## Object Storage parameters for Hive
|  Parameter | Description | Required | Default |
|---|---|---|---|
| gcp_cloud_key_secret | json file containing your Service Account's cloud credentials  | no |  |
| adl_oauth2_client_id | Azure SP ClientID | no |  |
| adl_oauth2_credential | Azure SP Password | no |  |
| adl_oauth2_refresh_url | Azure Oauth2 token refresh URL | no |  |
| s3_access_key | AWS IAM ACCESS_KEY | no |  |
| s3_endpoint | S3 endpoint | no |  |
| s3_region | AWS region to access the S3 endpoint | no |  |
| s3_secret_key | AWS IAM SECRET_KEY | no |  |
| abfs_access_key | Storage account access key | no |  |
| abfs_storage_account | Storage account name | no |  |
| abfs_auth_type | ABFS access type. Can be `accessKey` or `oauth` | no | oauth |
| abfs_client_id | Azure SP ClientID | no |  |
| abfs_endpoint | OAuth2 token refresh endpoint. You can find this in the Azure portal under: `Azure Active Directory > App Registrations > <your-app> > Endpoints` | no |  |
| abfs_secret | Azure SP Password | no |  |
| wasb_access_key | Storage account access key | no |  |
| wasb_storage_account | Storage account name | no |  |
___

## External RDS overrides
*If you have existing databases for these components, you can point to them with these override input parameters. Can be overridden on an individual basis.*
|  Parameter | Description | Required | Default |
|---|---|---|---|
| ex_hive_instance | Existing RDS instance to point your Hive Server to. If this is set, the application will point the Hive Server to this existing Hive metastore DB | no |  |
| ex_hive_port | Hive Database instance port | no |  |
| ex_hive_db | Hive database name (usually `hive` or `hms`) | no |  |
| ex_hive_db_user | User that can connect to the Hive Database | no |  |
| ex_hive_db_password | Password for the `ex_hive_db_user` | no |  |
| ex_ranger_instance | Existing RDS instance to point Ranger to. If set, the application will point to this existing Ranger database store. Note: To avoid any errors, you should also set all related `ex_ranger_?` passwords. | no |  |
| ex_ranger_port | Ranger Database instance port | no |  |
| ex_ranger_db | Ranger database name (usually `ranger`) | no |  |
| ex_ranger_root_user | Database admin user that can connect to the Ranger Database. This should be the `postgres` user or a suitable sysadmin user with the same privileges | no |  |
| ex_ranger_root_password | Password for the `ex_ranger_root_user` | no |  |
| ex_ranger_db_user | The database user that the Ranger application will use (default is `ranger`) | no |  |
| ex_ranger_db_password | Password for `ex_ranger_db_user` | no |  |
| ex_ranger_admin_pwd | Password for Internal account created by Ranger. Corresponds to `admin.passwords.admin` in the Ranger yaml file. Set this to an existing value when connecting to an existing Ranger database | no |  |
| ex_ranger_keyadmin_pwd | Password for Internal account created by Ranger. Corresponds to `admin.passwords.keyadmin` in the Ranger yaml file. Set this to an existing value when connecting to an existing Ranger database | no |  |
| ex_ranger_service_pwd | Password for Internal account created by Ranger. Corresponds to `admin.passwords.service` in the Ranger yaml file. Set this to an existing value when connecting to an existing Ranger database | no |  |
| ex_ranger_tagsync_pwd | Password for Internal account created by Ranger. Corresponds to `admin.passwords.tagsync` in the Ranger yaml file. Set this to an existing value when connecting to an existing Ranger database | no |  |
| ex_ranger_usersync_pwd | Password for Internal account created by Ranger. Corresponds to `admin.passwords.usersync` in the Ranger yaml file. Set this to an existing value when connecting to an existing Ranger database | no |  |
| ex_insights_instance | Existing RDS instance to point Starburst Insights to. When set, the application will point the Starburst Insights application to this existing data store. | no |  |
| ex_insights_port | Insights Database instance port | no |  |
| ex_insights_db | Insights database name (usually `insights`) | no |  |
| ex_insights_db_user | User that can connect to the Starburst Insights Database | no |  |
| ex_insights_db_password | Password for the `ex_insights_db_user` | no |  |