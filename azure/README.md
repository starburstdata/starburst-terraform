# Starburst-Terraform deployment for Azure
Deployment scripts built for Azure.

### Prerequisites
Ensure you have [azure cli](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli), [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/) and [helm](https://helm.sh/docs/intro/install/) installed and configured according to the cloud provider's documentation.

You should have existing user access to an Azure subscription with at least the following base IAM permissions set:
- `Owner`

OR

- `Contributor` and
- `User Access Administrator`

## Set up
1. Create a Service Principal in Azure for Terraform to work with. You will need the values returned by the create command later:
```
az login
az account set --subscription="<your_subscription_id>"
az ad sp create-for-rbac --name <your_sp_name> --role="Contributor" --scopes="/subscriptions/<your_subscription_id>"

```

2. Using the values returned in the json file, set the following global variables:
```
export ARM_CLIENT_ID=<appId-from-json>
export ARM_CLIENT_SECRET=<password-from-json>
export ARM_SUBSCRIPTION_ID=<your-subscription-id>
export ARM_TENANT_ID=<tenant-from-json>

```

3. Add the `User Access Administrator` IAM permission to the SP at the subscription level:
```
az role assignment create --assignee <service_principal_id_or_name> --role "User Access Administrator"
```
*Note: Use the SP name or id returned by the create-for-rbac command, not the displayName!*

4. Copy your Starburst license to a local directory on your client machine

5. Edit the `terraform.tfvars` file for your environment. For convenience and to ensure you don't accidentally check any sensitive values back into the GitHub repo, set any sensitive values in a separate input variables file ending in: `.auto.tfvars` (e.g. `sensitive.auto.tfvars` and add it to `.gitignore`) file or as global variables (TF_VAR_*) on your local machine:
    - `sb_license` *(point to your local file)*
    - `email`
    - `repo_username`
    - `repo_password`
    - `abfs_auth_type`
    - `abfs_client_id` *(your SP appId)*
    - `abfs_secret` *(your SP password)*

6. Create a workspace in Terraform for your deployment:
```
terraform workspace new ${your-workspace-name}
```
7. Initialize the Terraform environment:
```
terraform init
```
8. Deploy your environment:
```
terraform apply
```

## Undeploy
To delete all resources created in this deployment:
```
terraform destroy
```

## Important Info
AKS authentication tokens expire after an hour, so if you are attempting to tear down the infrastructure or apply any changes to it after a prolonged period of time, run:
```
terraform apply -target=module.k8s
```
to refresh the token beforehand.


___
## Input Parameters
|  Parameter | Description | Required | Default |
|---|---|---|---|
| admin_pass | Password override for the `admin_user`. Autogenerated by default. Set this when you want to define your own password for the admin user. Note: If you are deploying with Ranger with an existing Ranger database, set this to the existing Ranger admin user password | no |  |
| admin_user | Admin login credentials for Ranger | yes | sbadmin |
| create_bucket | Should the cloud storage bucket be created? | no | true |
| create_cloudbeaver | Should CloudBeaver be deployed? (https://cloudbeaver.io/) | no | true |
| create_hive | Should the Hive server resource be deployed? | no | true |
| create_k8s | Should the cloud K8s cluster be created? | no | true |
| create_mc | Should Mission Control be deployed? | no | true |
| create_nginx | Should the Nginx controller be deployed? | no | true |
| create_ranger | Should Ranger be deployed? | no | true |
| create_rds | Should the PostgreSQL instance be deployed? | no | true |
| create_trino | Should Starburst (Trino) be deployed? | no | true |
| create_vnet | Should the cloud vnet be created? | no | true |
| deployment_id | Custom deployment identifier override. When not set, the system will autogenerate a unique 8 alphanumeric value to identify the deployment infrastructure. If manually overriden, ensure that you are not using a value from an existing deployment. | no |  |
| dns_zone | The DNS zone to deploy applications to | no |  |
| dns_zone_name | the DNS name in Azure | no |  |
| dns_rg | The Resource Group where the DNS zone resides | yes |  |
| dns_sub | The `SUBSCRIPTION_ID` where the DNS zone resides. If your DNS zone resides in a different subscription, you'll need to set it here. | no |  |
| email | Your email address. Required if you need to deploy Nginx | no |  |
| ex_hive_server_url | An existing Hive Server to point your configuration to? | no |  |
| ex_resource_group | Name of existing Resource Group to use for this deployment | no |  |
| ex_subnet_name | Name of existing Subnet to launch the AKS cluster into. This should be added if `create_vnet` has been set to false. | no |  |
| ex_vnet_name | Name of existing VNet to launch the AKS cluster into. This should be added if `create_vnet` has been set to false | no |  |
| primary_node_type | The VM machine type in the primary pool | no | Standard_D8s_v3 |
| primary_pool_size | The size of the base pool (runs all apps besides Trino worker nodes) | no | 1 |
| reg_pass1 | Password override for addional user #1. Autogenerated by default. | no |  |
| reg_pass2 | Password override for addional user #2. Autogenerated by default. | no |  |
| reg_user1 | Additional user login to Starburst | yes | sbuser1 |
| reg_user2 | Additional user login to Starburst | yes | sbuser2 |
| region | The Azure location | yes |  |
| registry | Starburst registry in Harbor | yes | harbor.starburstdata.net/starburstdata |
| repo_password | Login password to the Harbor repository | yes |  |
| repo_username | Login user for the Harbor repository | yes |  |
| repo_version | Starburst release to be deployed. This includes all components | yes | 355.0.0 |
| repository | Starburst Helm repository | yes | https://harbor.starburstdata.net/chartrepo/starburstdata |
| sb_license | The Starburst license file | yes | N/A |
| starburst_version | The version of Starburst that Mission Control will deploy | yes | 355-e |
| tags | map of keys and values for tagging cloud resources | no | {manager = "starburst-terraform"} |
| use_ondemand | Should Terraform provision a on-demand instance worker node pool? | no | true |
| use_spot | Should Terraform provision a spot instance worker node pool? | no | false |
| wait_this_long | default time to wait on resources to finalize. Currently only used to wait for Postgres K8s LoadBalancer service to complete | no | 60s |
| worker_node_type | The VM machine type in the worker pool | no | Standard_D4s_v3 |
| worker_pool_max_size | The maximum size of the worker pool (worker pool is reserved for the Trino workers) | no | 10 |
| worker_pool_max_size | The maximum size of the worker pool (worker pool is reserved for the Trino workers) | no | 10 |
| worker_pool_min_size | The minimum size of the worker pool (worker pool is reserved for the Trino workers) | no | 1 |
| worker_pool_min_size | The minimum size of the worker pool (worker pool is reserved for the Trino workers) | no | 1 |
___
## Default Yaml Files
|  Parameter | Description | Required | Default |
|---|---|---|---|
| hive_yaml_file | Default values.yaml for `starburst-hive` Helm chart | yes | hms_values.yaml.tpl |
| trino_yaml_files | Default values.yaml for `starburst-enterprise` Helm chart. Note that there are multiple yaml files for this chart, broken out by related components. The application determines which files to layer onto the deployment based on the user's configuration selection criteria. e.g. if Ranger is not being deployed, then `trino_values.03.ranger.tpl` will be omitted. Note: that each file's configuration is successively applied - meaning that values in the later files will overwrite the same value in the previous files. The full path to the file should be included with the name. | yes | ["trino_values.01.base.tpl", "trino_values.02.auth.tpl", "trino_values.03.ranger.tpl", "trino_values.04.insights.tpl", "trino_values.05.catalogs.tpl", `custom_trino_yaml_file`] |
| ranger_yaml_file | Default values.yaml for `starburst-ranger` Helm chart | yes | ranger_values.yaml.tpl |
| mc_yaml_file | Default values.yaml for `starburst-mission-control` Helm chart | yes | mission_control.yaml.tpl |
| operator_yaml_file | Default values.yaml for `starburst-presto-helm-operator` Helm chart | yes | operator_values.yaml.tpl |
| postgres_yaml_file | Default values.yaml for Bitnami `postgresql` Helm chart | yes | postgresql.yaml.tpl |
| cloudbeaver_values.yaml.tpl | Default values.yaml for `CloudBeaver` Helm chart | yes | cloudbeaver_values.yaml.tpl |
| custom_trino_yaml_file | An optional user-defined yaml file for the Starburst-Enterprise deployment. Use this to override any of the default cluster configuration or to add additional data catalogs for your environment | no |  |
| custom_ranger_yaml_file | An optional user-defined yaml file for the Ranger deployment. Use this to override any of the default configuration | no |  |
| custom_hive_yaml_file | An optional user-defined yaml file for the Hive deployment. Use this to override any of the default configuration. | no |  |
___

## Object Storage parameters for Hive
|  Parameter | Description | Required | Default |
|---|---|---|---|
| gcp_cloud_key_secret | json file containing your Service Account's cloud credentials  | no |  |
| adl_oauth2_client_id | Azure SP ClientID | no |  |
| adl_oauth2_credential | Azure SP Password | no |  |
| adl_oauth2_refresh_url | Azure Oauth2 token refresh URL | no |  |
| s3_access_key | AWS IAM ACCESS_KEY | no |  |
| s3_endpoint | S3 endpoint | no |  |
| s3_region | AWS region to access the S3 endpoint | no |  |
| s3_secret_key | AWS IAM SECRET_KEY | no |  |
| abfs_access_key | Storage account access key | no |  |
| abfs_storage_account | Storage account name | no |  |
| abfs_auth_type | ABFS access type. Can be `accessKey` or `oauth` | no | oauth |
| abfs_client_id | Azure SP ClientID | no |  |
| abfs_endpoint | OAuth2 token refresh endpoint. You can find this in the Azure portal under: `Azure Active Directory > App Registrations > <your-app> > Endpoints` | no |  |
| abfs_secret | Azure SP Password | no |  |
| wasb_access_key | Storage account access key | no |  |
| wasb_storage_account | Storage account name | no |  |
___

## External RDS overrides
*If you have existing databases for these components, you can point to them with these override input parameters. Can be overridden on an individual basis.*
|  Parameter | Description | Required | Default |
|---|---|---|---|
| ex_hive_instance | Existing RDS instance to point your Hive Server to. If this is set, the application will point the Hive Server to this existing Hive metastore DB | no |  |
| ex_hive_port | Hive Database instance port | no |  |
| ex_hive_db | Hive database name (usually `hive` or `hms`) | no |  |
| ex_hive_db_user | User that can connect to the Hive Database | no |  |
| ex_hive_db_password | Password for the `ex_hive_db_user` | no |  |
| ex_mc_instance | Existing RDS instance to point Mission Control to. If this is set, the application will point MC to this existing data store. | no |  |
| ex_mc_port | Mission Control Database instance port | no |  |
| ex_mc_db | Mission Control database name (usually `mcdemo`) | no |  |
| ex_mc_db_user | User that can connect to the Mission Control Database | no |  |
| ex_mc_db_password | Password for the `ex_mc_db_user` | no |  |
| ex_ranger_instance | Existing RDS instance to point Ranger to. If set, the application will point to this existing Ranger database store. Note: To avoid any errors, you should also set all related `ex_ranger_?` passwords. | no |  |
| ex_ranger_port | Ranger Database instance port | no |  |
| ex_ranger_db | Ranger database name (usually `ranger`) | no |  |
| ex_ranger_root_user | Database admin user that can connect to the Ranger Database. This should be the `postgres` user or a suitable sysadmin user with the same privileges | no |  |
| ex_ranger_root_password | Password for the `ex_ranger_root_user` | no |  |
| ex_ranger_db_user | The database user that the Ranger application will use (default is `ranger`) | no |  |
| ex_ranger_db_password | Password for `ex_ranger_db_user` | no |  |
| ex_ranger_admin_pwd | Password for Internal account created by Ranger. Corresponds to `admin.passwords.admin` in the Ranger yaml file. Set this to an existing value when connecting to an existing Ranger database | no |  |
| ex_ranger_keyadmin_pwd | Password for Internal account created by Ranger. Corresponds to `admin.passwords.keyadmin` in the Ranger yaml file. Set this to an existing value when connecting to an existing Ranger database | no |  |
| ex_ranger_service_pwd | Password for Internal account created by Ranger. Corresponds to `admin.passwords.service` in the Ranger yaml file. Set this to an existing value when connecting to an existing Ranger database | no |  |
| ex_ranger_tagsync_pwd | Password for Internal account created by Ranger. Corresponds to `admin.passwords.tagsync` in the Ranger yaml file. Set this to an existing value when connecting to an existing Ranger database | no |  |
| ex_ranger_usersync_pwd | Password for Internal account created by Ranger. Corresponds to `admin.passwords.usersync` in the Ranger yaml file. Set this to an existing value when connecting to an existing Ranger database | no |  |
| ex_insights_instance | Existing RDS instance to point Starburst Insights to. When set, the application will point the Starburst Insights application to this existing data store. | no |  |
| ex_insights_port | Insights Database instance port | no |  |
| ex_insights_db | Insights database name (usually `event_logger`) | no |  |
| ex_insights_db_user | User that can connect to the Starburst Insights Database | no |  |
| ex_insights_db_password | Password for the `ex_insights_db_user` | no |  |